{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nimport os \nimport zipfile\nfrom tqdm import tqdm\nfrom glob import glob\nfrom shutil import copy, move","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-10-17T13:10:19.738670Z","iopub.execute_input":"2022-10-17T13:10:19.739064Z","iopub.status.idle":"2022-10-17T13:10:19.744217Z","shell.execute_reply.started":"2022-10-17T13:10:19.739025Z","shell.execute_reply":"2022-10-17T13:10:19.743428Z"},"trusted":true},"execution_count":73,"outputs":[]},{"cell_type":"markdown","source":"## Data Preparation","metadata":{}},{"cell_type":"code","source":"zipfile_dir = '../input/dogs-vs-cats/train.zip'\ntrain_dir = zipfile.ZipFile(zipfile_dir, 'r')\ntrain_dir.extractall()\n\nzipfile_dir = '../input/dogs-vs-cats/test1.zip'\ntest_dir = zipfile.ZipFile(zipfile_dir, 'r')\ntest_dir.extractall()","metadata":{"execution":{"iopub.status.busy":"2022-10-17T13:10:19.750274Z","iopub.execute_input":"2022-10-17T13:10:19.750568Z","iopub.status.idle":"2022-10-17T13:10:32.245764Z","shell.execute_reply.started":"2022-10-17T13:10:19.750540Z","shell.execute_reply":"2022-10-17T13:10:32.244883Z"},"trusted":true},"execution_count":74,"outputs":[]},{"cell_type":"code","source":"TRAIN_DIR = './train'\nTEST_DIR = './test1'\n\ntrain_set = os.listdir(TRAIN_DIR)\ntest_set = os.listdir(TEST_DIR)\n\n# print('#train images: %s'%len(train_set))\n# print('#test images: %s'%len(test_set))\n# print(train_set[:5])\n# print(test_set[:5])","metadata":{"execution":{"iopub.status.busy":"2022-10-17T13:10:32.247271Z","iopub.execute_input":"2022-10-17T13:10:32.247595Z","iopub.status.idle":"2022-10-17T13:10:32.271802Z","shell.execute_reply.started":"2022-10-17T13:10:32.247559Z","shell.execute_reply":"2022-10-17T13:10:32.271052Z"},"trusted":true},"execution_count":75,"outputs":[]},{"cell_type":"code","source":"dog_train_dir = './training/dog'\ndog_val_dir = './validation/dog'\ncat_train_dir = './training/cat'\ncat_val_dir = './validation/cat'\n\nfile_dirs = [dog_train_dir, dog_val_dir, cat_train_dir, cat_val_dir]\n\nfor dir in file_dirs:\n    os.makedirs(dir,exist_ok = True)","metadata":{"execution":{"iopub.status.busy":"2022-10-17T13:10:32.273557Z","iopub.execute_input":"2022-10-17T13:10:32.273904Z","iopub.status.idle":"2022-10-17T13:10:32.278512Z","shell.execute_reply.started":"2022-10-17T13:10:32.273868Z","shell.execute_reply":"2022-10-17T13:10:32.277755Z"},"trusted":true},"execution_count":76,"outputs":[]},{"cell_type":"code","source":"all_dogs = glob('./train/dog*jpg')\nall_cats = glob('./train/cat*jpg')\n\nprint(len(all_dogs))\nprint(len(all_cats))","metadata":{"execution":{"iopub.status.busy":"2022-10-17T13:10:32.280045Z","iopub.execute_input":"2022-10-17T13:10:32.280568Z","iopub.status.idle":"2022-10-17T13:10:32.381416Z","shell.execute_reply.started":"2022-10-17T13:10:32.280533Z","shell.execute_reply":"2022-10-17T13:10:32.380675Z"},"trusted":true},"execution_count":77,"outputs":[{"name":"stdout","text":"12500\n12500\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\ndogs_train, dogs_test = train_test_split(all_dogs, test_size=0.1, shuffle=True,random_state = 100)\ncats_train, cats_test = train_test_split(all_cats, test_size=0.1, shuffle=True,random_state = 100)","metadata":{"execution":{"iopub.status.busy":"2022-10-17T13:10:32.382469Z","iopub.execute_input":"2022-10-17T13:10:32.382773Z","iopub.status.idle":"2022-10-17T13:10:32.395675Z","shell.execute_reply.started":"2022-10-17T13:10:32.382740Z","shell.execute_reply":"2022-10-17T13:10:32.394657Z"},"trusted":true},"execution_count":78,"outputs":[]},{"cell_type":"code","source":"for name in tqdm(dogs_train):\n  copy(name , os.path.join(dog_train_dir , name.split('/')[-1]))\nfor name in tqdm(cats_train):\n  copy(name , os.path.join(cat_train_dir , name.split('/')[-1]))\n  \nfor name in tqdm(dogs_test):\n  copy(name , os.path.join(dog_val_dir , name.split('/')[-1]))\nfor name in tqdm(cats_test):\n  copy(name , os.path.join(cat_val_dir , name.split('/')[-1]))","metadata":{"execution":{"iopub.status.busy":"2022-10-17T13:10:32.397042Z","iopub.execute_input":"2022-10-17T13:10:32.397540Z","iopub.status.idle":"2022-10-17T13:10:38.467337Z","shell.execute_reply.started":"2022-10-17T13:10:32.397485Z","shell.execute_reply":"2022-10-17T13:10:38.466399Z"},"trusted":true},"execution_count":79,"outputs":[{"name":"stderr","text":"100%|██████████| 11250/11250 [00:01<00:00, 5763.34it/s]\n100%|██████████| 11250/11250 [00:03<00:00, 3068.50it/s]\n100%|██████████| 1250/1250 [00:00<00:00, 5716.24it/s]\n100%|██████████| 1250/1250 [00:00<00:00, 5841.86it/s]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Data Preprocessing","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\n\nTRAINING_DIR = './training'\ntrain_datagen = ImageDataGenerator(rescale=1 / 255)\ntrain_generator = train_datagen.flow_from_directory(\n    TRAINING_DIR,\n    batch_size=64,\n    class_mode='binary',\n    target_size=(150, 150)\n)\n\nVALIDATION_DIR = './validation'\nvalidation_datagen = ImageDataGenerator(rescale=1/255)\nvalidation_generator = validation_datagen.flow_from_directory(\n    VALIDATION_DIR,\n    batch_size = 64,\n    class_mode = 'binary',\n    target_size = (150, 150)\n)","metadata":{"execution":{"iopub.status.busy":"2022-10-17T13:10:38.468760Z","iopub.execute_input":"2022-10-17T13:10:38.469141Z","iopub.status.idle":"2022-10-17T13:10:39.693640Z","shell.execute_reply.started":"2022-10-17T13:10:38.469101Z","shell.execute_reply":"2022-10-17T13:10:39.692679Z"},"trusted":true},"execution_count":80,"outputs":[{"name":"stdout","text":"Found 22500 images belonging to 2 classes.\nFound 2500 images belonging to 2 classes.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Model Creation","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, Dense, MaxPool2D, Flatten, Dropout\n\nmodel = Sequential()\nmodel.add(Conv2D(64, (3,3), strides=(1,1), padding='same', activation='relu',kernel_initializer='he_normal',input_shape=(150, 150, 3)))\nmodel.add(Conv2D(64, (3,3), strides=(1,1), padding='same', activation='relu',kernel_initializer='he_normal'))\nmodel.add(MaxPool2D((2,2)))\nmodel.add(Dropout(0.4))\n\nmodel.add(Conv2D(128, (3,3), strides=(1,1), padding='same', activation='relu',kernel_initializer='he_normal'))\nmodel.add(Conv2D(128, (3,3), strides=(1,1), padding='same', activation='relu',kernel_initializer='he_normal'))\nmodel.add(Conv2D(128, (3,3), strides=(1,1), padding='same', activation='relu',kernel_initializer='he_normal'))\nmodel.add(MaxPool2D((2,2)))\nmodel.add(Dropout(0.4))\n\nmodel.add(Conv2D(256, (3,3), strides=(1,1), padding='same', activation='relu',kernel_initializer='he_normal'))\nmodel.add(Dropout(0.4))\nmodel.add(Conv2D(256, (3,3), strides=(1,1), padding='same', activation='relu',kernel_initializer='he_normal'))\nmodel.add(Dropout(0.4))\nmodel.add(Conv2D(256, (3,3), strides=(1,1), padding='same', activation='relu',kernel_initializer='he_normal'))\nmodel.add(MaxPool2D((2,2)))\nmodel.add(Dropout(0.4))\n\nmodel.add(Conv2D(512, (3,3), strides=(1,1), padding='same', activation='relu',kernel_initializer='he_normal'))\nmodel.add(Dropout(0.4))\nmodel.add(Conv2D(512, (3,3), strides=(1,1), padding='same', activation='relu',kernel_initializer='he_normal'))\nmodel.add(Dropout(0.4))\nmodel.add(Conv2D(512, (3,3), strides=(1,1), padding='same', activation='relu',kernel_initializer='he_normal'))\nmodel.add(MaxPool2D((2,2)))\nmodel.add(Dropout(0.4))\n\nmodel.add(Flatten())\nmodel.add(Dense(units=1024, activation='relu'))\nmodel.add(Dropout(0.4))\nmodel.add(Dense(units=1024, activation='relu'))\nmodel.add(Dropout(0.4))\nmodel.add(Dense(units=1024, activation='relu'))\nmodel.add(Dropout(0.4))\nmodel.add(Dense(units=1, activation='sigmoid'))","metadata":{"execution":{"iopub.status.busy":"2022-10-17T13:10:39.696324Z","iopub.execute_input":"2022-10-17T13:10:39.696867Z","iopub.status.idle":"2022-10-17T13:10:39.869681Z","shell.execute_reply.started":"2022-10-17T13:10:39.696825Z","shell.execute_reply":"2022-10-17T13:10:39.868908Z"},"trusted":true},"execution_count":81,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2022-10-17T13:10:39.871406Z","iopub.execute_input":"2022-10-17T13:10:39.871858Z","iopub.status.idle":"2022-10-17T13:10:39.890878Z","shell.execute_reply.started":"2022-10-17T13:10:39.871822Z","shell.execute_reply":"2022-10-17T13:10:39.890074Z"},"trusted":true},"execution_count":82,"outputs":[{"name":"stdout","text":"Model: \"sequential_4\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d_44 (Conv2D)           (None, 150, 150, 64)      1792      \n_________________________________________________________________\nconv2d_45 (Conv2D)           (None, 150, 150, 64)      36928     \n_________________________________________________________________\nmax_pooling2d_16 (MaxPooling (None, 75, 75, 64)        0         \n_________________________________________________________________\ndropout_44 (Dropout)         (None, 75, 75, 64)        0         \n_________________________________________________________________\nconv2d_46 (Conv2D)           (None, 75, 75, 128)       73856     \n_________________________________________________________________\nconv2d_47 (Conv2D)           (None, 75, 75, 128)       147584    \n_________________________________________________________________\nconv2d_48 (Conv2D)           (None, 75, 75, 128)       147584    \n_________________________________________________________________\nmax_pooling2d_17 (MaxPooling (None, 37, 37, 128)       0         \n_________________________________________________________________\ndropout_45 (Dropout)         (None, 37, 37, 128)       0         \n_________________________________________________________________\nconv2d_49 (Conv2D)           (None, 37, 37, 256)       295168    \n_________________________________________________________________\ndropout_46 (Dropout)         (None, 37, 37, 256)       0         \n_________________________________________________________________\nconv2d_50 (Conv2D)           (None, 37, 37, 256)       590080    \n_________________________________________________________________\ndropout_47 (Dropout)         (None, 37, 37, 256)       0         \n_________________________________________________________________\nconv2d_51 (Conv2D)           (None, 37, 37, 256)       590080    \n_________________________________________________________________\nmax_pooling2d_18 (MaxPooling (None, 18, 18, 256)       0         \n_________________________________________________________________\ndropout_48 (Dropout)         (None, 18, 18, 256)       0         \n_________________________________________________________________\nconv2d_52 (Conv2D)           (None, 18, 18, 512)       1180160   \n_________________________________________________________________\ndropout_49 (Dropout)         (None, 18, 18, 512)       0         \n_________________________________________________________________\nconv2d_53 (Conv2D)           (None, 18, 18, 512)       2359808   \n_________________________________________________________________\ndropout_50 (Dropout)         (None, 18, 18, 512)       0         \n_________________________________________________________________\nconv2d_54 (Conv2D)           (None, 18, 18, 512)       2359808   \n_________________________________________________________________\nmax_pooling2d_19 (MaxPooling (None, 9, 9, 512)         0         \n_________________________________________________________________\ndropout_51 (Dropout)         (None, 9, 9, 512)         0         \n_________________________________________________________________\nflatten_4 (Flatten)          (None, 41472)             0         \n_________________________________________________________________\ndense_16 (Dense)             (None, 1024)              42468352  \n_________________________________________________________________\ndropout_52 (Dropout)         (None, 1024)              0         \n_________________________________________________________________\ndense_17 (Dense)             (None, 1024)              1049600   \n_________________________________________________________________\ndropout_53 (Dropout)         (None, 1024)              0         \n_________________________________________________________________\ndense_18 (Dense)             (None, 1024)              1049600   \n_________________________________________________________________\ndropout_54 (Dropout)         (None, 1024)              0         \n_________________________________________________________________\ndense_19 (Dense)             (None, 1)                 1025      \n=================================================================\nTotal params: 52,351,425\nTrainable params: 52,351,425\nNon-trainable params: 0\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"check_point_path = './best.h5'\nmodel_checkpoint = tf.keras.callbacks.ModelCheckpoint(\n    filepath = check_point_path,\n    monitor = 'val_accuracy',\n    save_weights_only=False,\n    save_best_only=True,\n    verbose=1\n)","metadata":{"execution":{"iopub.status.busy":"2022-10-17T13:10:39.892738Z","iopub.execute_input":"2022-10-17T13:10:39.893069Z","iopub.status.idle":"2022-10-17T13:10:39.897789Z","shell.execute_reply.started":"2022-10-17T13:10:39.893035Z","shell.execute_reply":"2022-10-17T13:10:39.896897Z"},"trusted":true},"execution_count":83,"outputs":[]},{"cell_type":"code","source":"model.compile(optimizer = tf.keras.optimizers.Adam(0.0005,decay=1e-5),\n             loss = 'binary_crossentropy',\n             metrics = ['acc'])","metadata":{"execution":{"iopub.status.busy":"2022-10-17T13:10:39.899043Z","iopub.execute_input":"2022-10-17T13:10:39.899403Z","iopub.status.idle":"2022-10-17T13:10:39.915694Z","shell.execute_reply.started":"2022-10-17T13:10:39.899369Z","shell.execute_reply":"2022-10-17T13:10:39.914951Z"},"trusted":true},"execution_count":84,"outputs":[]},{"cell_type":"code","source":"print('Num Params : ',model.count_params())\nmodel_history = model.fit(\n    train_generator,\n    epochs=10,\n    verbose=1,\n    callbacks = [model_checkpoint],\n    validation_data=validation_generator\n)","metadata":{"execution":{"iopub.status.busy":"2022-10-17T13:10:39.918562Z","iopub.execute_input":"2022-10-17T13:10:39.918813Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Num Params :  52351425\nEpoch 1/10\n352/352 [==============================] - 93s 262ms/step - loss: 4.5826 - acc: 0.5011 - val_loss: 0.6940 - val_acc: 0.5000\nEpoch 2/10\n352/352 [==============================] - 91s 259ms/step - loss: 0.6923 - acc: 0.5166 - val_loss: 0.6938 - val_acc: 0.5000\nEpoch 3/10\n352/352 [==============================] - 93s 265ms/step - loss: 0.6923 - acc: 0.5187 - val_loss: 0.7012 - val_acc: 0.5000\nEpoch 4/10\n352/352 [==============================] - 94s 265ms/step - loss: 0.6782 - acc: 0.5662 - val_loss: 0.6355 - val_acc: 0.6332\nEpoch 5/10\n352/352 [==============================] - ETA: 0s - loss: 0.6254 - acc: 0.6306","output_type":"stream"}]},{"cell_type":"markdown","source":"## Model Evaluation","metadata":{}},{"cell_type":"markdown","source":"Plotting Loss and Accuracy","metadata":{}},{"cell_type":"code","source":"%matplotlib inline\n\nimport matplotlib.image  as mpimg\nimport matplotlib.pyplot as plt\n\n#-----------------------------------------------------------\n# Retrieve a list of list results on training and test data\n# sets for each training epoch\n#-----------------------------------------------------------\nacc=model_history.history['acc']\nval_acc=model_history.history['val_acc']\nloss=model_history.history['loss']\nval_loss=model_history.history['val_loss']\n\nepochs=range(len(acc)) # Get number of epochs\n\n#------------------------------------------------\n# Plot training and validation accuracy per epoch\n#------------------------------------------------\nplt.plot(epochs, acc, 'r')\nplt.plot(epochs, val_acc, 'b')\nplt.title('Training and validation accuracy')\nplt.xlabel('epochs')\nplt.ylabel('accuracy')\nplt.legend([\"Training Accuracy\",\"Validation Accuracy\"])\nplt.show()\n\n#------------------------------------------------\n# Plot training and validation loss per epoch\n#------------------------------------------------\nplt.plot(epochs, loss, 'r')\nplt.plot(epochs, val_loss, 'b')\nplt.title('Training and validation loss')\nplt.title('Training and validation loss')\nplt.xlabel('epochs')\nplt.ylabel('loss')\nplt.legend([\"Training Loss\",\"Validation Loss\"])\nplt.show()\n\n# Desired output. Charts with training and validation metrics. ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_file = os.listdir(\"./test1\")\ntest_df = pd.DataFrame({\n    'filename': test_file\n})\ntest_df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"TESTING_DIR = './test1'\ntest_generator = train_datagen.flow_from_dataframe(\n    test_df,\n    directory = TESTING_DIR,\n    x_col='filename',\n    y_col=None,\n    batch_size=64,\n    target_size=(150, 150),\n    shuffle = False,\n    class_mode = None\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_generator.reset()\ny_pred = model.predict(test_generator)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"To see the class mapping of dogs and cats, we have to see class_indices from training dataset","metadata":{}},{"cell_type":"code","source":"train_generator.class_indices","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's make labels","metadata":{}},{"cell_type":"code","source":"y_pred_classification = np.where(y_pred > 0.5, 1, 0)\ny_pred_classification","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Seeing some results","metadata":{}},{"cell_type":"code","source":"test_generator.reset()\ntest_images = test_generator[0][:9]\n\nfig, ax = plt.subplots(3,3)\nfig.set_size_inches(10,10)\nfor i, img in enumerate(test_images):\n    ax[i//3][i%3].imshow(img)\n    if y_pred_classification[i]==1:\n        label = 'Dog'\n    else:\n        label = 'Cat'\n    ax[i//3][i%3].set_title(label)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Visualizing first 9 filters","metadata":{}},{"cell_type":"code","source":"model.layers","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"first_conv = model.layers[0]\noutput_layer1 = first_conv(test_images)[4]\n\nprint(output_layer1.shape)\nfig, ax = plt.subplots(3,3)\nfig.set_size_inches(10,10)\nfor i in range(9):\n  ax[i//3][i%3].imshow(output_layer1[:,:,i])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Submition","metadata":{}},{"cell_type":"code","source":"submission = pd.read_csv('../input/dogs-vs-cats/sampleSubmission.csv')\nsubmission['label'] = y_pred_classification\nsubmission","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission.to_csv('submission.csv',index='False')","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}