{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nimport os \nimport zipfile\nfrom tqdm import tqdm\nfrom glob import glob\nfrom shutil import copy, move","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-10-17T12:49:12.413675Z","iopub.execute_input":"2022-10-17T12:49:12.414052Z","iopub.status.idle":"2022-10-17T12:49:12.419066Z","shell.execute_reply.started":"2022-10-17T12:49:12.414011Z","shell.execute_reply":"2022-10-17T12:49:12.418175Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"markdown","source":"## Data Preparation","metadata":{}},{"cell_type":"code","source":"zipfile_dir = '../input/dogs-vs-cats/train.zip'\ntrain_dir = zipfile.ZipFile(zipfile_dir, 'r')\ntrain_dir.extractall()\n\nzipfile_dir = '../input/dogs-vs-cats/test1.zip'\ntest_dir = zipfile.ZipFile(zipfile_dir, 'r')\ntest_dir.extractall()","metadata":{"execution":{"iopub.status.busy":"2022-10-17T12:49:12.420728Z","iopub.execute_input":"2022-10-17T12:49:12.421298Z","iopub.status.idle":"2022-10-17T12:49:25.368812Z","shell.execute_reply.started":"2022-10-17T12:49:12.421260Z","shell.execute_reply":"2022-10-17T12:49:25.367945Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"TRAIN_DIR = './train'\nTEST_DIR = './test1'\n\ntrain_set = os.listdir(TRAIN_DIR)\ntest_set = os.listdir(TEST_DIR)\n\n# print('#train images: %s'%len(train_set))\n# print('#test images: %s'%len(test_set))\n# print(train_set[:5])\n# print(test_set[:5])","metadata":{"execution":{"iopub.status.busy":"2022-10-17T12:49:25.370447Z","iopub.execute_input":"2022-10-17T12:49:25.370791Z","iopub.status.idle":"2022-10-17T12:49:25.396558Z","shell.execute_reply.started":"2022-10-17T12:49:25.370758Z","shell.execute_reply":"2022-10-17T12:49:25.395841Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"dog_train_dir = './training/dog'\ndog_val_dir = './validation/dog'\ncat_train_dir = './training/cat'\ncat_val_dir = './validation/cat'\n\nfile_dirs = [dog_train_dir, dog_val_dir, cat_train_dir, cat_val_dir]\n\nfor dir in file_dirs:\n    os.makedirs(dir,exist_ok = True)","metadata":{"execution":{"iopub.status.busy":"2022-10-17T12:49:25.398396Z","iopub.execute_input":"2022-10-17T12:49:25.398724Z","iopub.status.idle":"2022-10-17T12:49:25.403550Z","shell.execute_reply.started":"2022-10-17T12:49:25.398689Z","shell.execute_reply":"2022-10-17T12:49:25.402564Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"all_dogs = glob('./train/dog*jpg')\nall_cats = glob('./train/cat*jpg')\n\nprint(len(all_dogs))\nprint(len(all_cats))","metadata":{"execution":{"iopub.status.busy":"2022-10-17T12:49:25.404742Z","iopub.execute_input":"2022-10-17T12:49:25.405258Z","iopub.status.idle":"2022-10-17T12:49:25.513792Z","shell.execute_reply.started":"2022-10-17T12:49:25.405223Z","shell.execute_reply":"2022-10-17T12:49:25.512851Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"12500\n12500\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\ndogs_train, dogs_test = train_test_split(all_dogs, test_size=0.1, shuffle=True,random_state = 100)\ncats_train, cats_test = train_test_split(all_cats, test_size=0.1, shuffle=True,random_state = 100)","metadata":{"execution":{"iopub.status.busy":"2022-10-17T12:49:25.514951Z","iopub.execute_input":"2022-10-17T12:49:25.515301Z","iopub.status.idle":"2022-10-17T12:49:25.528728Z","shell.execute_reply.started":"2022-10-17T12:49:25.515267Z","shell.execute_reply":"2022-10-17T12:49:25.527950Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"for name in tqdm(dogs_train):\n  copy(name , os.path.join(dog_train_dir , name.split('/')[-1]))\nfor name in tqdm(cats_train):\n  copy(name , os.path.join(cat_train_dir , name.split('/')[-1]))\n  \nfor name in tqdm(dogs_test):\n  copy(name , os.path.join(dog_val_dir , name.split('/')[-1]))\nfor name in tqdm(cats_test):\n  copy(name , os.path.join(cat_val_dir , name.split('/')[-1]))","metadata":{"execution":{"iopub.status.busy":"2022-10-17T12:49:25.531136Z","iopub.execute_input":"2022-10-17T12:49:25.531466Z","iopub.status.idle":"2022-10-17T12:49:30.071393Z","shell.execute_reply.started":"2022-10-17T12:49:25.531432Z","shell.execute_reply":"2022-10-17T12:49:30.070415Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stderr","text":"100%|██████████| 11250/11250 [00:02<00:00, 5274.77it/s]\n100%|██████████| 11250/11250 [00:01<00:00, 5801.32it/s]\n100%|██████████| 1250/1250 [00:00<00:00, 5451.06it/s]\n100%|██████████| 1250/1250 [00:00<00:00, 5722.24it/s]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Data Preprocessing","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\n\nTRAINING_DIR = './training'\ntrain_datagen = ImageDataGenerator(rescale=1 / 255)\ntrain_generator = train_datagen.flow_from_directory(\n    TRAINING_DIR,\n    batch_size=64,\n    class_mode='binary',\n    target_size=(150, 150)\n)\n\nVALIDATION_DIR = './validation'\nvalidation_datagen = ImageDataGenerator(rescale=1/255)\nvalidation_generator = validation_datagen.flow_from_directory(\n    VALIDATION_DIR,\n    batch_size = 64,\n    class_mode = 'binary',\n    target_size = (150, 150)\n)","metadata":{"execution":{"iopub.status.busy":"2022-10-17T12:49:30.073313Z","iopub.execute_input":"2022-10-17T12:49:30.073667Z","iopub.status.idle":"2022-10-17T12:49:31.061329Z","shell.execute_reply.started":"2022-10-17T12:49:30.073619Z","shell.execute_reply":"2022-10-17T12:49:31.060403Z"},"trusted":true},"execution_count":32,"outputs":[{"name":"stdout","text":"Found 22500 images belonging to 2 classes.\nFound 2500 images belonging to 2 classes.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Model Creation","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, Dense, MaxPool2D, Flatten, Dropout\n\nmodel = Sequential()\nmodel.add(Conv2D(64, (3,3), strides=(1,1), padding='same', activation='relu',kernel_initializer='he_normal',input_shape=(150, 150, 3)))\nmodel.add(Conv2D(64, (3,3), strides=(1,1), padding='same', activation='relu',kernel_initializer='he_normal'))\nmodel.add(MaxPool2D((2,2)))\nmodel.add(Dropout(0.4))\n\nmodel.add(Conv2D(128, (3,3), strides=(1,1), padding='same', activation='relu',kernel_initializer='he_normal'))\nmodel.add(Conv2D(128, (3,3), strides=(1,1), padding='same', activation='relu',kernel_initializer='he_normal'))\nmodel.add(Conv2D(128, (3,3), strides=(1,1), padding='same', activation='relu',kernel_initializer='he_normal'))\nmodel.add(MaxPool2D((2,2)))\nmodel.add(Dropout(0.4))\n\nmodel.add(Conv2D(256, (3,3), strides=(1,1), padding='same', activation='relu',kernel_initializer='he_normal'))\nmodel.add(Dropout(0.4))\nmodel.add(Conv2D(256, (3,3), strides=(1,1), padding='same', activation='relu',kernel_initializer='he_normal'))\nmodel.add(Dropout(0.4))\nmodel.add(Conv2D(256, (3,3), strides=(1,1), padding='same', activation='relu',kernel_initializer='he_normal'))\nmodel.add(MaxPool2D((2,2)))\nmodel.add(Dropout(0.4))\n\nmodel.add(Conv2D(512, (3,3), strides=(1,1), padding='same', activation='relu',kernel_initializer='he_normal'))\nmodel.add(Dropout(0.4))\nmodel.add(Conv2D(512, (3,3), strides=(1,1), padding='same', activation='relu',kernel_initializer='he_normal'))\nmodel.add(Dropout(0.4))\nmodel.add(Conv2D(512, (3,3), strides=(1,1), padding='same', activation='relu',kernel_initializer='he_normal'))\nmodel.add(MaxPool2D((2,2)))\nmodel.add(Dropout(0.4))\n\nmodel.add(Flatten())\nmodel.add(Dense(units=1024, activation='relu'))\nmodel.add(Dropout(0.4))\nmodel.add(Dense(units=1024, activation='relu'))\nmodel.add(Dropout(0.4))\nmodel.add(Dense(units=1024, activation='relu'))\nmodel.add(Dropout(0.4))\nmodel.add(Dense(units=1, activation='sigmoid'))","metadata":{"execution":{"iopub.status.busy":"2022-10-17T12:49:31.062630Z","iopub.execute_input":"2022-10-17T12:49:31.063106Z","iopub.status.idle":"2022-10-17T12:49:31.240476Z","shell.execute_reply.started":"2022-10-17T12:49:31.063068Z","shell.execute_reply":"2022-10-17T12:49:31.239652Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2022-10-17T12:49:31.241733Z","iopub.execute_input":"2022-10-17T12:49:31.242077Z","iopub.status.idle":"2022-10-17T12:49:31.262795Z","shell.execute_reply.started":"2022-10-17T12:49:31.242038Z","shell.execute_reply":"2022-10-17T12:49:31.262050Z"},"trusted":true},"execution_count":34,"outputs":[{"name":"stdout","text":"Model: \"sequential_1\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d_11 (Conv2D)           (None, 150, 150, 64)      1792      \n_________________________________________________________________\nconv2d_12 (Conv2D)           (None, 150, 150, 64)      36928     \n_________________________________________________________________\nmax_pooling2d_4 (MaxPooling2 (None, 75, 75, 64)        0         \n_________________________________________________________________\ndropout_11 (Dropout)         (None, 75, 75, 64)        0         \n_________________________________________________________________\nconv2d_13 (Conv2D)           (None, 75, 75, 128)       73856     \n_________________________________________________________________\nconv2d_14 (Conv2D)           (None, 75, 75, 128)       147584    \n_________________________________________________________________\nconv2d_15 (Conv2D)           (None, 75, 75, 128)       147584    \n_________________________________________________________________\nmax_pooling2d_5 (MaxPooling2 (None, 37, 37, 128)       0         \n_________________________________________________________________\ndropout_12 (Dropout)         (None, 37, 37, 128)       0         \n_________________________________________________________________\nconv2d_16 (Conv2D)           (None, 37, 37, 256)       295168    \n_________________________________________________________________\ndropout_13 (Dropout)         (None, 37, 37, 256)       0         \n_________________________________________________________________\nconv2d_17 (Conv2D)           (None, 37, 37, 256)       590080    \n_________________________________________________________________\ndropout_14 (Dropout)         (None, 37, 37, 256)       0         \n_________________________________________________________________\nconv2d_18 (Conv2D)           (None, 37, 37, 256)       590080    \n_________________________________________________________________\nmax_pooling2d_6 (MaxPooling2 (None, 18, 18, 256)       0         \n_________________________________________________________________\ndropout_15 (Dropout)         (None, 18, 18, 256)       0         \n_________________________________________________________________\nconv2d_19 (Conv2D)           (None, 18, 18, 512)       1180160   \n_________________________________________________________________\ndropout_16 (Dropout)         (None, 18, 18, 512)       0         \n_________________________________________________________________\nconv2d_20 (Conv2D)           (None, 18, 18, 512)       2359808   \n_________________________________________________________________\ndropout_17 (Dropout)         (None, 18, 18, 512)       0         \n_________________________________________________________________\nconv2d_21 (Conv2D)           (None, 18, 18, 512)       2359808   \n_________________________________________________________________\nmax_pooling2d_7 (MaxPooling2 (None, 9, 9, 512)         0         \n_________________________________________________________________\ndropout_18 (Dropout)         (None, 9, 9, 512)         0         \n_________________________________________________________________\nflatten_1 (Flatten)          (None, 41472)             0         \n_________________________________________________________________\ndense_4 (Dense)              (None, 1024)              42468352  \n_________________________________________________________________\ndropout_19 (Dropout)         (None, 1024)              0         \n_________________________________________________________________\ndense_5 (Dense)              (None, 1024)              1049600   \n_________________________________________________________________\ndropout_20 (Dropout)         (None, 1024)              0         \n_________________________________________________________________\ndense_6 (Dense)              (None, 1024)              1049600   \n_________________________________________________________________\ndropout_21 (Dropout)         (None, 1024)              0         \n_________________________________________________________________\ndense_7 (Dense)              (None, 1)                 1025      \n=================================================================\nTotal params: 52,351,425\nTrainable params: 52,351,425\nNon-trainable params: 0\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"check_point_path = './best.h5'\nmodel_checkpoint = tf.keras.callbacks.ModelCheckpoint(\n    filepath = check_point_path,\n    monitor = 'val_accuracy',\n    save_weights_only=False,\n    save_best_only=True,\n    verbose=1\n)","metadata":{"execution":{"iopub.status.busy":"2022-10-17T12:49:31.264758Z","iopub.execute_input":"2022-10-17T12:49:31.265089Z","iopub.status.idle":"2022-10-17T12:49:31.270043Z","shell.execute_reply.started":"2022-10-17T12:49:31.265053Z","shell.execute_reply":"2022-10-17T12:49:31.269133Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"model.compile(optimizer = tf.keras.optimizers.RMSprop(0.0005,decay=1e-5),\n             loss = 'binary_crossentropy',\n             metrics = ['acc'])","metadata":{"execution":{"iopub.status.busy":"2022-10-17T12:49:31.271416Z","iopub.execute_input":"2022-10-17T12:49:31.271784Z","iopub.status.idle":"2022-10-17T12:49:31.291433Z","shell.execute_reply.started":"2022-10-17T12:49:31.271748Z","shell.execute_reply":"2022-10-17T12:49:31.290688Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"print('Num Params : ',model.count_params())\nmodel_history = model.fit(\n    train_generator,\n    epochs=10,\n    verbose=1,\n    callbacks = [model_checkpoint],\n    validation_data=validation_generator\n)","metadata":{"execution":{"iopub.status.busy":"2022-10-17T12:49:31.292713Z","iopub.execute_input":"2022-10-17T12:49:31.293082Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Num Params :  52351425\nEpoch 1/10\n352/352 [==============================] - 94s 262ms/step - loss: 8.3697 - acc: 0.5133 - val_loss: 0.6936 - val_acc: 0.5000\nEpoch 2/10\n352/352 [==============================] - 92s 261ms/step - loss: 0.7212 - acc: 0.5237 - val_loss: 0.7097 - val_acc: 0.5016\nEpoch 3/10\n352/352 [==============================] - 92s 261ms/step - loss: 0.6658 - acc: 0.6177 - val_loss: 0.6073 - val_acc: 0.7016\nEpoch 4/10\n352/352 [==============================] - 92s 261ms/step - loss: 0.5926 - acc: 0.6882 - val_loss: 0.5855 - val_acc: 0.6628\nEpoch 5/10\n352/352 [==============================] - 92s 261ms/step - loss: 0.5619 - acc: 0.7206 - val_loss: 0.5356 - val_acc: 0.7240\nEpoch 6/10\n352/352 [==============================] - 91s 259ms/step - loss: 0.4951 - acc: 0.7655 - val_loss: 0.4320 - val_acc: 0.7956\nEpoch 7/10\n 65/352 [====>.........................] - ETA: 1:10 - loss: 0.4504 - acc: 0.7980","output_type":"stream"}]},{"cell_type":"markdown","source":"## Model Evaluation","metadata":{}},{"cell_type":"markdown","source":"Plotting Loss and Accuracy","metadata":{}},{"cell_type":"code","source":"%matplotlib inline\n\nimport matplotlib.image  as mpimg\nimport matplotlib.pyplot as plt\n\n#-----------------------------------------------------------\n# Retrieve a list of list results on training and test data\n# sets for each training epoch\n#-----------------------------------------------------------\nacc=model_history.history['acc']\nval_acc=model_history.history['val_acc']\nloss=model_history.history['loss']\nval_loss=model_history.history['val_loss']\n\nepochs=range(len(acc)) # Get number of epochs\n\n#------------------------------------------------\n# Plot training and validation accuracy per epoch\n#------------------------------------------------\nplt.plot(epochs, acc, 'r')\nplt.plot(epochs, val_acc, 'b')\nplt.title('Training and validation accuracy')\nplt.xlabel('epochs')\nplt.ylabel('accuracy')\nplt.legend([\"Training Accuracy\",\"Validation Accuracy\"])\nplt.show()\n\n#------------------------------------------------\n# Plot training and validation loss per epoch\n#------------------------------------------------\nplt.plot(epochs, loss, 'r')\nplt.plot(epochs, val_loss, 'b')\nplt.title('Training and validation loss')\nplt.title('Training and validation loss')\nplt.xlabel('epochs')\nplt.ylabel('loss')\nplt.legend([\"Training Loss\",\"Validation Loss\"])\nplt.show()\n\n# Desired output. Charts with training and validation metrics. ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_file = os.listdir(\"./test1\")\ntest_df = pd.DataFrame({\n    'filename': test_file\n})\ntest_df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"TESTING_DIR = './test1'\ntest_generator = train_datagen.flow_from_dataframe(\n    test_df,\n    directory = TESTING_DIR,\n    x_col='filename',\n    y_col=None,\n    batch_size=64,\n    target_size=(150, 150),\n    shuffle = False,\n    class_mode = None\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_generator.reset()\ny_pred = model.predict(test_generator)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"To see the class mapping of dogs and cats, we have to see class_indices from training dataset","metadata":{}},{"cell_type":"code","source":"train_generator.class_indices","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's make labels","metadata":{}},{"cell_type":"code","source":"y_pred_classification = np.where(y_pred > 0.5, 1, 0)\ny_pred_classification","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Seeing some results","metadata":{}},{"cell_type":"code","source":"test_generator.reset()\ntest_images = test_generator[0][:9]\n\nfig, ax = plt.subplots(3,3)\nfig.set_size_inches(10,10)\nfor i, img in enumerate(test_images):\n    ax[i//3][i%3].imshow(img)\n    if y_pred_classification[i]==1:\n        label = 'Dog'\n    else:\n        label = 'Cat'\n    ax[i//3][i%3].set_title(label)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Visualizing first 9 filters","metadata":{}},{"cell_type":"code","source":"model.layers","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"first_conv = model.layers[0]\noutput_layer1 = first_conv(test_images)[4]\n\nprint(output_layer1.shape)\nfig, ax = plt.subplots(3,3)\nfig.set_size_inches(10,10)\nfor i in range(9):\n  ax[i//3][i%3].imshow(output_layer1[:,:,i])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Submition","metadata":{}},{"cell_type":"code","source":"submission = pd.read_csv('../input/dogs-vs-cats/sampleSubmission.csv')\nsubmission['label'] = y_pred_classification\nsubmission","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission.to_csv('submission.csv',index='False')","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}